{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOWPDZet1Q0EfGTZyNmtkkh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arshad-huh/100-Days-Challenge/blob/main/22_da_sql.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "User Engagement Analysis For RESTAURANT SUCCESS"
      ],
      "metadata": {
        "id": "P0_MzkcoRxlz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "About YELP\n",
        "\n",
        "Yelp is a web and mobile platform that functions as a crowd-sourced local\n",
        "business review site. Users can submit reviews, photos, and tips about\n",
        "businesses, while also browsing information and ratings left by others."
      ],
      "metadata": {
        "id": "t4dIRvv3R2Vj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "AGENDA\n",
        "• Problem Statement\n",
        "• Research Objectives\n",
        "• Hypothesis\n",
        "• Data Overview\n",
        "• Analysis and Findings\n",
        "• Recommendations"
      ],
      "metadata": {
        "id": "aszUcGm0VsgD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem Statement\n",
        "\n",
        "In a competitive market like the restaurant industry, understanding the\n",
        "factors that influence business success is crucial for stakeholders.\n",
        "Utilizing the Yelp dataset, this project aims to investigate the relationship\n",
        "between user engagement (reviews, tips, and check-ins) and business\n",
        "success metrics (review count, ratings) for restaurants."
      ],
      "metadata": {
        "id": "iZCReTnQV1Wb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rsearch Objectives\n",
        "\n",
        "Quantity the correlation\n",
        "between user engagement\n",
        "(reviews, tips, check-ins) and\n",
        "review count/ average star\n",
        "rating.\n",
        "\n",
        "Analyze the impact of\n",
        "sentiment on review count and\n",
        "average star rating.\n",
        "\n",
        "Time Trends in User\n",
        "Engagement"
      ],
      "metadata": {
        "id": "W5WDPUmpV9jD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hypothesis\n",
        "\n",
        "• Higher levels of user engagement (more reviews, tips, and check-ins)\n",
        "correlate with higher review counts and ratings for restaurants.\n",
        "\n",
        "• Positive sentiment expressed in reviews and tips contributes to higher\n",
        "overall ratings and review counts for restaurants.\n",
        "\n",
        "• Consistent engagement over time is positively associated with\n",
        "sustained business success for restaurants."
      ],
      "metadata": {
        "id": "1tuRIQm6Wht7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Overview\n",
        "\n",
        "• This dataset is a subset of Yelp and has information about busir\n",
        "across 8 metropolitan areas in the USA and Canada.\n",
        "\n",
        "• The original data is shared by Yelp as JSON files.\n",
        "\n",
        "• The five JSON files are business, review, user, tip and checkin.\n",
        "\n",
        "• The JSON files are stored in the database for easy retrieval of data."
      ],
      "metadata": {
        "id": "pm-L9vYsW1G0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis and Findings\n"
      ],
      "metadata": {
        "id": "vUNFQuCbXScz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'yelp-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F10100%2F3316532%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240530%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240530T074316Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D72098f4777054f9473f9289a3b2d4a208a6a11b17135c8aa499b70c6454ea8ba93e7f38730c8063920687f462d9dbdd9cb1054d69afa8a5ecee37ad47c97ac5acd7890a49f34187aae550e6656ff651d9be103e9461cc42491f02a2666b8d5a769c8a4bf1d40c1645b1ce3eb4989dfc7a9128acd2256a432c951023af70bd8df5800864c9bd33a696d49bdfad6d84e400dbbcf3d21eb75755310a8f2cf666a73c36368eaf27ed0b283918e8420de768a2fa5efc73453deab2663443e3151920947fa0342a1ee79391d8905d11bd8e6998c09c68966a503ae406096804b7ee1c7ac9a22d669d0b83e69e48f1a69a28d8151336f35e53c7b260ca7e73e8c2bfa26'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVBrJ3PzePEd",
        "outputId": "6678fc42-b0ed-4290-f8e3-3438dc617c27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading yelp-dataset, 4374983563 bytes compressed\n",
            "[==================================================] 4374983563 bytes downloaded\n",
            "Downloaded and uncompressed: yelp-dataset\n",
            "Data source import complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sqlalchemy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs7_bbWWh-Ec",
        "outputId": "49415331-7692-4c95-fc12-90ad7e700f94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.10/dist-packages (2.0.30)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy) (4.11.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy) (3.0.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "with open('/input/yelp-dataset/yelp_academic_dataset_business.json', 'r') as f:\n",
        "  business_data = [json.loads(line) for line in f]\n",
        "business_df = pd.DataFrame(business_data)\n",
        "\n",
        "with open('/input/yelp-dataset/yelp_academic_dataset_checkin.json', 'r') as f:\n",
        "  checkin_data = [json.loads(line) for line in f]\n",
        "checkin_df = pd.DataFrame(checkin_data)\n",
        "\n",
        "with open('/input/yelp-dataset/yelp_academic_dataset_review.json', 'r') as f:\n",
        "  review_data = [json.loads(line) for line in f]\n",
        "review_df = pd.DataFrame(review_data)\n",
        "\n",
        "with open('/input/yelp-dataset/yelp_academic_dataset_tip.json', 'r') as f:\n",
        "  tip_data = [json. loads(line) for line in f]\n",
        "tip_df = pd.DataFrame(tip_data)\n",
        "\n",
        "with open('/input/yelp-dataset/yelp_academic_dataset_user.json', 'r') as f:\n",
        "  user_data = [json.loads(line) for line in f]\n",
        "user_df = pd.DataFrame(user_data)"
      ],
      "metadata": {
        "id": "YE2_ark3eu62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(business_df.shape)\n",
        "print(checkin_df.shape)\n",
        "print(review_df.shape)\n",
        "print(tip_df.shape)\n",
        "print(user_df.shape)"
      ],
      "metadata": {
        "id": "u_hBlv_khkM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "business_df.drop(['attributes', 'hours'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "QO5nOKhDigGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "engine = create_engine('sqlite:///yelp.db')\n",
        "\n",
        "def load_dataframe(df, table_name, engine):\n",
        "  df.to_sql(table_name, con=engine, if_exists='replace', index=False)\n",
        "\n",
        "# Load each DataFrame into a separate table\n",
        "load_dataframe(business_df, 'business', engine)\n",
        "load_dataframe(review_df, 'review', engine)\n",
        "load_dataframe(user_df, 'user', engine)\n",
        "load_dataframe(tip_df, 'tip', engine)\n",
        "load_dataframe(checkin_df, 'checkin', engine)"
      ],
      "metadata": {
        "id": "vSW7iGjriu55"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import sqlite3\n",
        "import folium\n",
        "from geopy.geocoders import Nominatin\n",
        "from matplotlib.colors import LinearSegmentedColormap\n",
        "from IPython.display import display\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "CaWDtaJmjzll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Database Connection"
      ],
      "metadata": {
        "id": "1IvzZESykQAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conn = sqlite3.connect('yelp.db')"
      ],
      "metadata": {
        "id": "X2xG3xV1kS2T"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}